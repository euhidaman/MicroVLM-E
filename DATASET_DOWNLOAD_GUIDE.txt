================================================================================
MicroVLM-E Dataset Download Guide
================================================================================

PREREQUISITES
-------------

1. Install img2dataset:
   pip install img2dataset

2. HuggingFace Authentication (for LAION dataset):

   Method 1 (Recommended):
   huggingface-cli login
   [Enter your token when prompted]

   Method 2 (Environment Variable):
   Windows: $env:HF_TOKEN="your_token_here"
   Linux/Mac: export HF_TOKEN="your_token_here"

   Get token from: https://huggingface.co/settings/tokens


DOWNLOAD COMMANDS
-----------------

# Download everything (recommended for full training):
python scripts/download_datasets.py --all

# Minimal download (quick start, ~30 GB):
python scripts/download_datasets.py --datasets coco vqav2 llava_instruct

# Check what's already downloaded:
python scripts/download_datasets.py --status


WHAT GETS DOWNLOADED AUTOMATICALLY
-----------------------------------

✓ COCO 2017 images and annotations (~25 GB)
✓ VQA datasets (VQAv2, OK-VQA, A-OKVQA, GQA)
✓ RefCOCO/RefCOCO+/RefCOCOg from HuggingFace
✓ LLaVA instruction tuning data from HuggingFace
✓ OCR-VQA from Google Drive
✓ SBU Captions

✓ CC3M:
  - Downloads TSV files
  - Automatically runs img2dataset to download images
  - Expect ~70-80% success rate (many dead URLs - this is normal)
  - Takes several hours

✓ LAION-COCO:
  - Downloads from HuggingFace (requires authentication)
  - Automatically runs img2dataset to download images
  - Some URLs may be dead (normal)


WHAT REQUIRES MANUAL SETUP
---------------------------

⊘ Flickr30k (OPTIONAL - not required for training):
  1. Create Kaggle account: https://www.kaggle.com/
  2. Get API credentials: https://www.kaggle.com/docs/api
  3. Run: kaggle datasets download -d hsankesara/flickr-image-dataset


DATASET SIZES
-------------

Essential datasets (~30 GB):
- COCO 2017: ~25 GB
- VQAv2: ~200 MB (uses COCO images)
- LLaVA-150K: ~300 MB (uses COCO images)

Full dataset (~300-400 GB):
- COCO: ~25 GB
- CC3M: ~150 GB
- LAION-COCO: ~50 GB
- GQA: ~20 GB
- SBU: ~10 GB
- VQA datasets: ~500 MB
- RefCOCO datasets: ~150 MB
- OCR-VQA: ~5 GB
- LLaVA: ~300 MB


TROUBLESHOOTING
---------------

Problem: "img2dataset not found"
Solution: pip install img2dataset

Problem: "LAION download failed - 401 Unauthorized"
Solution: You need HuggingFace authentication
         Run: huggingface-cli login

Problem: "RefCOCO download failed - connection error"
Solution: Old UNC server URLs are broken. Make sure you have the latest
         version of download_datasets.py that uses HuggingFace instead.

Problem: "Many CC3M URLs failing"
Solution: This is NORMAL. CC3M has ~30% dead URLs. The script will continue
         downloading valid URLs. You'll get ~70-80% of images successfully.

Problem: "CC3M/LAION not downloading images, just printing commands"
Solution: Install img2dataset: pip install img2dataset
         The script will automatically run img2dataset after TSV/parquet download.

Problem: "Out of disk space"
Solution: Download only essential datasets:
         python scripts/download_datasets.py --datasets coco vqav2 llava_instruct


MONITORING DOWNLOADS
--------------------

Download progress is logged to Weights & Biases:
- Project: MicroVLM-E-datasets-logs
- Run names: microvlme-datasets-1log, microvlme-datasets-2log, etc.
- View at: https://wandb.ai

The --status command shows local progress:
- Downloaded files and sizes
- Failed downloads with reasons
- Image counts
- Disk space usage


RECOMMENDED DOWNLOAD ORDER
--------------------------

For fastest training start:

1. Essential only (10 minutes, ~30 GB):
   python scripts/download_datasets.py --datasets coco vqav2 llava_instruct

2. Add VQA datasets (30 minutes, +25 GB):
   python scripts/download_datasets.py --datasets gqa ocrvqa okvqa aokvqa

3. Add grounding datasets (5 minutes, +150 MB):
   python scripts/download_datasets.py --datasets refcoco refcoco_plus refcocog

4. Add pretraining data (several hours, +200 GB):
   python scripts/download_datasets.py --datasets cc3m laion

You can start training after step 1!


UNDERSTANDING CC3M AND LAION DOWNLOADS
---------------------------------------

These datasets work in two stages:

Stage 1: Metadata Download (fast)
  - CC3M: Downloads TSV files with image URLs and captions
  - LAION: Downloads Parquet files with image URLs and captions

Stage 2: Image Download (slow - automatic)
  - img2dataset reads the URLs and downloads actual images
  - Processes in parallel for speed
  - Resizes images to 256x256
  - Saves in webdataset format
  - Takes 2-6 hours depending on:
    * Internet speed
    * Number of processes/threads
    * URL validity rate

The script handles both stages automatically if img2dataset is installed.


DATASET USAGE IN TRAINING
--------------------------

Stage 1 (Alignment): COCO, CC3M, LAION
Stage 2 (LoRA): All datasets
Stage 3 (Instruction): LLaVA, VQA datasets
Stage 4 (Multi-task): All datasets

You can adjust which datasets are used in train_configs/*.yaml


AFTER DOWNLOAD
--------------

Verify downloads with:
python scripts/download_datasets.py --status

Expected output:
✓ Shows all downloaded datasets
✓ Lists image counts
✓ Shows disk usage
✓ Reports any failures

Then start training:
python train.py --cfg-path train_configs/stage1_alignment.yaml

================================================================================

